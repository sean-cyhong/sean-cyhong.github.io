---
layout: about
title: About
permalink: /
subtitle: Research Assistant <br> <a href='https://www.iis.sinica.edu.tw/en/index.html'>Institute of Information Science Academia Sinica</a>, <a href='https://homepage.iis.sinica.edu.tw/~liutyng/'>Computer Vision & Machine Learning Lab</a>.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
services: true
social: true # includes social icons at the bottom of the page
---

I am a research assistant in the [Computer Vision & Machine Learning Lab](https://homepage.iis.sinica.edu.tw/~liutyng/) at the [Institute of Information Science (IIS)](https://www.iis.sinica.edu.tw/en/index.html), Academia Sinica, under the mentorship of Prof. [Tyng-Luh Liu](https://homepage.iis.sinica.edu.tw/pages/liutyng/index_en.html). Prior to join IIS, I completed the Master's degree in [Integrated Circuits & Systems group (ICS)](https://giee.ntu.edu.tw/en/ics_lecture.php) from the [Graduate Institute of Electronics Engineering](https://giee.ntu.edu.tw/en/) at [National Taiwan University (NTU)](https://www.ntu.edu.tw/english/). This followed my undergraduate studies at [National Chiao Tung University (NCTU)](https://en.wikipedia.org/wiki/National_Chiao_Tung_University).

My research primarily focuses on three areas: [1] unsupervised representation learning, free from human annotations. [2] enhancing traditional computer vision problems through the application of diffusion/consistency models. [3] advancing the efficiency of Large Multimodal Models (LMMs). Overall, my work lies at the nexus of of computer vision and energy-efficient computing, particularly emphasizing unsupervised (self-supervised) representation learning and the development of compact yet effective machine learning models for computer vision applications. Looking ahead, my research aims to address three interrelated questions:

<ol>
How can we learn representations from large, unlabeled natural datasets to construct comprehensive world models or simulators?
How can diffusion/consistency mechanisms improve existing computer vision solutions?
How can we enhance the efficiency of Large Multimodal Models for IoT devices through algorithmic and hardware structural co-optimization?
</ol>

Aside from my research, I have a keen interest in exploring innovative vision applications that incorporate various modalities, including point clouds and audio.

<img src="{{ '/assets/img/NCTU.png' | relative_url }}"   width="100" style="vertical-align: middle;border-radius:50%;">
<img src="{{ '/assets/img/NTU.jpg' | relative_url }}"  width="100" style="vertical-align: middle;border-radius:50%;">
<img src="{{ '/assets/img/A.png' | relative_url }}"   width="100" style="vertical-align: middle;border-radius:50%;">
<img src="{{ '/assets/img/IIS.jpg' | relative_url }}"   width="100" style="vertical-align: middle;border-radius:50%;">

