---
layout: about
title: About
permalink: /
subtitle: Research Assistant <br> <a href='https://www.iis.sinica.edu.tw/en/index.html'>Institute of Information Science Academia Sinica</a>, <a href='https://homepage.iis.sinica.edu.tw/~liutyng/'>Computer Vision & Machine Learning Lab</a>.

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

news: true # includes a list of news items
latest_posts: false # includes a list of the newest posts
selected_papers: true # includes a list of papers marked as "selected={true}"
services: true
social: true # includes social icons at the bottom of the page
---

I am a research assistant in the [Computer Vision & Machine Learning Lab](https://homepage.iis.sinica.edu.tw/~liutyng/) at the [Institute of Information Science (IIS)](https://www.iis.sinica.edu.tw/en/index.html), Academia Sinica, under the mentorship of Prof. [Tyng-Luh Liu](https://homepage.iis.sinica.edu.tw/pages/liutyng/index_en.html). Prior to joining IIS, I completed the Master's degree in [Integrated Circuits & Systems group (ICS)](https://giee.ntu.edu.tw/en/ics_lecture.php) from the [Graduate Institute of Electronics Engineering](https://giee.ntu.edu.tw/en/) at [National Taiwan University (NTU)](https://www.ntu.edu.tw/english/). This followed my undergraduate studies at [National Chiao Tung University (NCTU)](https://en.wikipedia.org/wiki/National_Chiao_Tung_University).

My research has primarily focused on [1] representation learning without supervision by human annotations. [2] tackling existing computer vision problems via leveraging diffusion/consistency models. [3] efficient Large Multimodal Models (LMMs). <br>

Overall, my work lies at the nexus of of <b>computer vision</b> and <b>energy-efficient tiny-ML models</b>, particularly emphasizing unsupervised (self-supervised) representation learning and the development of compact yet effective machine learning models for computer vision applications. Looking ahead, my research aims to address three interrelated questions:

<ol>
<li>Can we learn representations from abundant, unlabeled natural datasets to construct comprehensive world models or simulators?</li>
<li>Can we utlize the diffusion/consistency mechanism to boost the existing computer vision solution?</li>
<li>Can we leverage algorithm and hardware structure co-optimization to enhance the efficiency of Large Multimodal Models for IoT devices?</li>
</ol>

Aside from my research, I have a keen interest in exploring innovative vision applications that incorporate various modalities, including point clouds and audio.

<img src="{{ '/assets/img/NCTU.png' | relative_url }}"   width="100" style="vertical-align: middle;border-radius:50%;">
<img src="{{ '/assets/img/NTU.jpg' | relative_url }}"  width="100" style="vertical-align: middle;border-radius:50%;">
<img src="{{ '/assets/img/A.png' | relative_url }}"   width="100" style="vertical-align: middle;border-radius:50%;">
<img src="{{ '/assets/img/IIS.jpg' | relative_url }}"   width="100" style="vertical-align: middle;border-radius:50%;">

